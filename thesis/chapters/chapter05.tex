\chapter{Discussion}\label{ch:discussion}

%The measurements performed above don't seem to lead to straightforward results,
%that clearly favor one approach over the other. This might be explained by the
%multitude of influencing factors, that can impact the performance.

Based on the results displayed previously, one can conclude that for
cross-domain retrieval, an approach based on Canny edge detection and local
features performs better than global approaches. Of the similarity measures
used to compare the images' signatures, histogram intersection provides the
most consistent performance. 
The advantage over the global descriptors, however, is not large and poorly
chosen parameter values can lead to the global descriptors outperforming the
local variants.

When both the query image and the database images are sketches, the situation
is reversed. The precision and recall statistics for the global LUMA+MEAN
pipeline show a slight advantage over the local LUMA+PMEAN variant. This is
probably strongly influenced by the images used in the retrieval benchmark, as
will be discussed below.

\section{Structural Influences}

The intention underlying this thesis was to perform an evaluation of the
applicability of the Fast Discrete Curvelet Transform to sketch-based image
retrieval. It therefore seemed reasonable to otherwise choose methods and
algorithms that are frequently used in this area of research in order to
minimize the number of unknowns involved. The choice of edge detection steps
includes established algorithms such as the Sobel and Canny operators as well
as the recently published gPb contour detector
\autocite{arbelaez_contour_2011}. The simple sampling methods are designed
based on prior research, that suggests, that keypoint-based sampling barely
provided any advantages at the cost of increased processing and complexity
\autocite{nowak_sampling_2006}. Finally, the clustering and ranking process is
constructed using the often-used k-means clustering algorithm, several
established distance metrics and the TF-IDF weighting scheme, that has been
successfully applied to information retrieval for some time.

Considering the large differences between the image domains used in the
cross-domain evaluation, it is not surprising that the most successful pipeline
configurations involve edge detecting preprocessing steps. But even without
such steps, that try to bridge the gap between the query and database image
domains, the Curvelet transform on plain images produces viable results in some
cases. For example, the global LUMA+MEAN pipeline
(Figure~\ref{fig:pipeline_global_luma_mean}) combined with the cosine
similarity measure performs almost as good as the best global configuration
(Table~\ref{tab:results_global_luma_mean}). This indicates that the
scale-specificity enables the Curvelet transform to extract meaningful edges
from photographs on its own.

\section{Parameter Choices}

Since many of the processing steps are based on commonly-used algorithms,
literature already presented reasonable starting values for the evaluation. As
the experiments in section \ref{sec:results_parameters} show, the initial
values already produce competitive results. The best parameter values seem to
strike a balance between losing information due to small resolution and
becoming overly sensitive to noise or unrelated image background. For local
sampling methods, a neighborhood size of $\frac{1}{3}$ of the image dimensions
repeatedly performs best. A value of $\sigma=1.5$ for the Gaussian blur of the
Canny edge detector appears to be suitable to extract the edges that correspond
to a human sketch of the object or scene. The advantage of an angluar resultion
larger than $N_{\theta}=12$ for the curvelet transform is probably limited by
to the poor accuracy of hand-drawn sketches.

\section{Benchmark Dataset Influences}

Before making generalized statements based on the results above, several
properties of the benchmark datasets must taken into account. In particular,
the fact that the global descriptor outperforms the local descriptor in the
intra-domain benchmark can probably be attributed to the nature of the images.
As stated by Eitz et al.\ \autocite{eitz_how_2012}, the sketches have been
scaled to a fixed size of the bounding box and centered in a $256 \times 256$
pixel image. This constitutes a form of preprocessing that is suited to bypass
the lack of translation invariance of the global descriptor. While that
invariance would be expected to be an advantage of the local descriptors in
general, it can be a confounding factor in this case, which may contribute to
the relatively poor results. Whether translation invariance beyond the
slight fuzzyness introduced by the sampling method would be desirable at all,
clearly depends on the images involved and the expectations of the user. If the
user sketches a scene in order to find photographs with similar composition,
disregarding the location of drawn features would be counterproductive.

So while the intra-domain dataset's normalization of the images seems to favor
global descriptors, the cross-domain dataset mixes query intents and image
types. Some sketches and images depict single objects with varying degrees of
context and background, while others capture whole scenes or small objects
within a larger composition. Differences in descriptor performance within such
a diverse image set is to be expected. And indeed, as shown in
Figure~\ref{fig:results_distribution} there are a few query images in the
cross-domain benchmark, for which the proposed solutions consistently don't
lead to good rankings. 

But even in the intra-domain evaluation (Figure~\ref{fig:results_precision})
there are significant differences in descriptor performance between different
sketch categories. Reasons for that might be that the sketches or images
contain too much distracting patterns or that the datasets contain several
representations of the same object, that are visually not very similar. 

The overall picture is, that each set of pipeline components and parameter
values might only be suitable for a limited range of image types. When the
system is designed for a more specific purpose, its performance can probably
exceed the results shown above by a large margin.
