\chapter{Introduction}\label{ch:introduction}

\section{Motivation}

With the proliferation of cheap and powerful mobile devices over the last
years, the amount of images uploaded to the internet each day is growing
seemingly without limits. New medical devices produce high-resolution image
data in large amounts as the costs of building and running these devices go
down. Detailed imagery in various wavelengths of the sky and the planets in our
solar system is captured by more and more telescopes on earth and in space. The
amount of visual information created today is so large, that no human could
ever hope to gain a comprehensive overview. That is why increasing attention is
being directed at computer-aided classification and retrieval of those
information.

At the core of the research into content-based image retrieval (CBIR) lies the
need to be able to access the growing repositories of visual data in a
convenient and efficient manner.  In this context "convenient" describes the
ability for the user to express the query without a complex reformulation of
the intent to make it accessible to the query processor. At the same time the
computational efficiency becomes more important as the amount of data to search
grows. This issue becomes even more critical as the use of mobile,
power-limited devices increases across many areas of application, such as
autonomous vehicles or handheld augmented reality devices.

Research into text-based information retrieval has brought into existence many
statistical methods to query a potentially large body of text using text as the
query input. This preserves the close mapping of the intent of the user to the
expression of the query and thereby makes the process accessible to users
without knowledge about the internal workings of the retrieval system.
Providing the means to access a large amount of visual data using a system with
similar properties has turned out not to be an easy problem to solve. Using
text-based querying for that purpose depends on the ability to reliably label
visual data, which would require solving the general object recognition problem
first \autocite{smeulders_content-based_2000}. To avoid that obstacle and to
free the retrieval system from the requirement of translating between textual
and visual information, many methods to search an image database using visual
similarity have been developed.

While the goals of those systems are very similar, they differ considerably in
many aspects of the processing pipeline. The query input ranges from example
images over drawings to predicates describing color and shape distribution.
Similarly, the structure and content of the databases and the means by which
the systems query and rank the results vary significantly. This thesis focuses
on evaluating a system that uses hand-drawn sketches as inputs to query
databases of either photographs or contour images. The fast discrete curvelet
transform \autocite{candes_fast_2006} is used to analyse the images, because it
should be especially adept at representing curve-like discontinuities of
various sizes.

\section{Outline}

\autoref{ch:background} presents the structure of the problem and prior
solutions. The following \autoref{ch:solution} proposes several variations of a
particular solution using the Fast Discrete Curvelet Transform
\autocite{candes_fast_2006}. The experimental setup and its results are
documented in \autoref{ch:results} and discussed in \autoref{ch:discussion}. In
\autoref{ch:conclusion} several possible conclusions are drawn and pointers
towards future research are given.

