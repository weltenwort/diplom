\chapter{Conclusion}\label{ch:conclusion}

This thesis examined the suitability of image descriptors for sketch-based
image retrieval. In particular, the theoretical background of the Fast Discrete
Curvelet Transform was explained and its use in combination with established
retrieval system architectures was demonstrated. Querying a database of
photographs using hand-drawn sketches was used as a representative example of
cross-domain image retrieval.

The theoretical discussion in literature of the Curvelet transform's advantages
over related algorithms such as the Gabor filter indicate, it might be
especially well suited for sketch-based image retrieval. To evaluate this,
common structural features of retrieval systems were examined and based on that
several processing pipeline variations, that utilize the Fast Discrete Curvelet
Transform, were implemented. This included descriptors relying on global image
information as well as ones using local neighborhoods to extract image
features. The performance of these pipelines was measured using both a
cross-domain benchmark and an intra-domain benchmark.

The results showed, that the curvelet-based descriptors can compete with other
descriptors described in literature, although the implementations used in this
paper did not exceed the best among those. For cross-domain retrieval a local
feature descriptor, that performed edge detection on the photographs, was most
successful. The intra-domain evaluation on the other hand resulted in a global
descriptors showing slightly better performance. In both cases the advantage of
one type over the other was small and might be attributed to limitations of the
benchmark dataset. Also noticeable in both cases was a broad distribution of
the resulting values for different query images and categories, that was
consistent across several descriptors. This could be an indication, that the
semantic and sensory gaps were too large for the algorithms to overcome, for
example when the photographs or sketches contained large amounts of clutter or
a category included ambiguous representations of an object.

\section{Future Research}\label{sec:conclusion_future_research}

As discussed above, the descriptors performed far below average for a few
queries and categories. Looking at why the algorithms behaved so differently
with specific images or finding common properties in the outlier images could
give precious hints for making the descriptors applicable more generally. In
the same way, it could provide insights into which descriptors would be best
for specific applications, such as medical image analysis or industrial quality
    control.

Another possible improvement could be to use algorithmically or heuristically
determined values for the parameters, which were static in the above
benchmarks, on a per-image basis. It would even be thinkable to dynamically
exclude or include certain preprocessing steps depending on characteristics of
the image and features in the database. If a quick analysis determines that a
sobel operator extracts too few edges, for example, it could be replaced by a
Canny edge extraction.

To make the retrieval process more robust despite the varying nature of the
images, a database that contains several signatures extracted using different
descriptors for each image can enable a CBIR system to create multiple
rankings. This would be especially useful in scenarios, in which the user can
interactively manipulate the query preferences to express the intent behind the
query.

The results presented above show that it can be worth considering the FDCT when
building such systems in the future.
