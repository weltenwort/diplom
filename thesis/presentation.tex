% vim: set fdm=marker:
\pdfminorversion=4
\documentclass[mathserif]{beamer}

% theme {{{
%\usetheme{Antibes}
\usetheme[compress]{Dresden}
%\usecolortheme{dolphin}
\usecolortheme{rose}
%\usefonttheme{serif}
%}}}

% packages {{{
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{caption}
\usepackage{tikz}
%}}}

% config {{{
\input{illustrations/graphics_settings.tex}
\pgfplotstableset{
    every table/.style={font=\scriptsize},
}
\pgfplotsset{
    hbarplot/.append style={
        bar width=8pt,
    },
}
\setlength{\tabcolsep}{3pt}
%\captionsetup{font=scriptsize,labelfont=scriptsize}
%\renewcommand{\captionfont}{\tiny}
%\renewcommand{\captionlabelfont}{\tiny}
%\setlength{\intextsep}{5.0pt plus 2.0pt minus 2.0pt}
%}}}

% title {{{
\title{Analysis of Image Tranforms for Sketch-based Retrieval}
\subtitle{Diploma Thesis}
\author{Felix St체rmer}
\institute[Fakult채t IV - TU Berlin]
{
    Technische Universit채t Berlin\\
    Fakult채t IV - Elektrotechnik und Informatik\\
    Computer Graphics
}
\date{02.11.2012}
\subject{Computer Graphics}
%}}}

\begin{document}
% document {{{

% titlepage {{{
\begin{frame}
  \titlepage
\end{frame}
%}}}

% toc {{{
\begin{frame}{Outline}
  \tableofcontents
  % You might wish to add the option [pausesections]
\end{frame}
%}}}

% introduction and background {{{
\section{Introduction and Background}
\subsection{Motivation and Challenges of CBIR}
\begin{frame}{Motivation}
    \begin{columns}
        \begin{column}{.5\textwidth}
            \begin{itemize}
                \item Increasing amount of visual information in
                    \begin{itemize}
                        \item the internet
                        \item medicine
                        \item astronomy
                    \end{itemize}
                \item Manual search largely infeasible
                \item Textual queries require cognitive effort by human and machine
                \item Sketches allow for easy \emph{expression of query intent}
            \end{itemize}
        \end{column}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \includegraphics[width=.9\textwidth]{illustrations/medical_image}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Challenges of CBIR}
    \begin{block}{The Semantic Gap}
        \begin{quote}
            ``The semantic gap is the \textbf{lack of coincidence} between the
            information that one can extract from the \textbf{visual data} and
            the \textbf{interpretation} that the same data have for a user in a
            given situation.'' -- Smeulders et al.
        \end{quote}
    \end{block}
    \begin{block}{The Sensory Gap}
        \begin{quote}
            ``The sensory gap is the gap between the \textbf{object in the
            world} and the information in a (computational) description derived
            from a \textbf{recording of that scene}.'' -- Smeulders et al.
        \end{quote}
    \end{block}
\end{frame}

\subsection{Prior Work}
\begin{frame}{Prior Work on Human Recognition}
    \begin{figure}
        \includegraphics[width=.9\textwidth]{illustrations/related_work/curvelet_faces_mandal09}
        \caption{``Face recognition using curvelet based PCA.'', T. Mandal and Q. M.J Wu, ICPR 2008}
    \end{figure}
\end{frame}

\begin{frame}{Prior Work on Human Recognition}
    \begin{figure}
        \includegraphics[width=.12\textwidth]{illustrations/related_work/hog_dalal05_1}
        \includegraphics[width=.12\textwidth]{illustrations/related_work/hog_dalal05_2}
        \includegraphics[width=.12\textwidth]{illustrations/related_work/hog_dalal05_3}
        \includegraphics[width=.12\textwidth]{illustrations/related_work/hog_dalal05_4}
        \includegraphics[width=.12\textwidth]{illustrations/related_work/hog_dalal05_5}
        \includegraphics[width=.12\textwidth]{illustrations/related_work/hog_dalal05_6}
        \includegraphics[width=.12\textwidth]{illustrations/related_work/hog_dalal05_7}
        \caption{``Histograms of oriented gradients for human detection'', Dalal and Triggs, CVPR 2005}
    \end{figure}
\end{frame}

\begin{frame}{Prior Work on Visual Codebooks}
    \begin{columns}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_1}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_2}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_3}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_4}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_5}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_6}\\
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_7}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_8}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_9}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_10}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_11}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_12}\\
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_13}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_14}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_15}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_16}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_17}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_18}\\
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_19}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_20}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_21}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_22}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_23}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_24}\\
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_25}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_26}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_27}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_28}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_29}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict1_30}
            \end{figure}
            \begin{figure}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_1}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_2}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_3}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_4}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_5}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_6}\\
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_7}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_8}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_9}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_10}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_11}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_12}\\
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_13}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_14}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_15}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_16}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_17}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_18}\\
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_19}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_20}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_21}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_22}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_23}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_24}\\
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_25}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_26}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_27}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_28}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_29}
                \includegraphics[width=.5cm]{illustrations/related_work/video_google/video_google_dict2_30}
            \end{figure}
        \end{column}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \includegraphics[width=.4\textwidth]{illustrations/related_work/video_google/query_1_large}
                \includegraphics[width=.4\textwidth]{illustrations/related_work/video_google/query_1_small}\\
                \includegraphics[width=.4\textwidth]{illustrations/related_work/video_google/query_2_large}
                \includegraphics[width=.4\textwidth]{illustrations/related_work/video_google/query_2_small}
                \caption{``Video Google: A text retrieval approach to object matching in videos'', Sivic and Zisserman, ICCV 2003}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Prior Work on Scene Classification}
    \begin{figure}
        \includegraphics[width=.9\textwidth]{illustrations/related_work/pyramid_lazebnik09}
        \caption{``Spatial pyramid matching'', Lazebnik et al., 2009}
    \end{figure}
\end{frame}

\subsection{Anatomy of a CBIR System}
\begin{frame}{Anatomy of a CBIR System}
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \begin{figure}
                \includegraphics[width=.9\textwidth]{illustrations/cbir_anatomy_query_cropped}
                \caption{Global Descriptors}
                \label{fig:anatomy_global}
            \end{figure}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{figure}
                \includegraphics[width=.9\textwidth]{illustrations/cbir_anatomy_query_local_cropped}
                \caption{Local Descriptors}
                \label{fig:anatomy_local}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}
% }}}

% solution {{{
\section{Proposed Solution}
\subsection{Proposed Retrieval Pipelines}
\begin{frame}{Proposed Retrieval Pipelines (Global)}
    \begin{figure}
        \input{illustrations/pipelines/global_summary.tex}
    \end{figure}
\end{frame}

\begin{frame}{Proposed Retrieval Pipelines (Local)}
    \begin{figure}
        \input{illustrations/pipelines/local_summary.tex}
    \end{figure}
\end{frame}

\subsection{Acquisition}
\begin{frame}{Acquisition}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \begin{figure}
                \includegraphics[width=\textwidth]{illustrations/input_example_color}
                \caption{Original Image}
            \end{figure}
        \end{column}
        \begin{column}{0.5\textwidth}
            \only<1>{
                \begin{figure}
                    \includegraphics[width=\textwidth]{illustrations/input_example_luma}
                    \caption{Luma Conversion}
                \end{figure}
            }
            \only<2>{
                \begin{figure}
                    \includegraphics[width=\textwidth]{illustrations/input_example_canny}
                    \caption{Canny Operator}
                \end{figure}
            }
            \only<3>{
                \begin{figure}
                    \includegraphics[width=\textwidth]{illustrations/input_example_sobel}
                    \caption{Sobel Operator}
                \end{figure}
            }
            \only<4>{
                \begin{figure}
                    \includegraphics[width=\textwidth]{illustrations/input_example_segment}
                    \caption{gPb-owt-ucm Transform}
                \end{figure}
            }
        \end{column}
    \end{columns}
\end{frame}

\subsection{The Curvelet Transform}
\begin{frame}{Properties of the Curvelet Transform}
    \begin{itemize}
        \item An extension of the wavelet transform
        \item Localized in \emph{position}, \emph{scale} and \emph{orientation}
        \item Curvelets obey parabolic scaling: $width \approx length^2$
        \item Approximation error along edges using $m$ largest coefficients decays with $\frac{log(m)^3}{m^2}$ (compare $\frac{1}{m}$ for wavelets)
        \item Defined and applied in frequency domain as $\hat{\varphi}_{j, l, k}$ using the inverse Fourier Transforms:
            \begin{equation*}
                c(j, l, k) := \langle f, \varphi_{j, l, k} \rangle = \int_{\mathbb{R}^2} f(x) \overline{\varphi_{j, l, k}(x)} dx
            \end{equation*}
    \end{itemize}
\end{frame}

\begin{frame}{Constructing the Curvelets}
    \begin{columns}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \input{illustrations/curvelet_tilings/continuous_tiling_freq.tex}
                \caption{Frequency Domain}
            \end{figure}
        \end{column}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \input{illustrations/curvelet_tilings/continuous_tiling_spatial.tex}
                \caption{Spatial Domain}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Example Curvelets}
    \begin{columns}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \includegraphics[width=.5\textwidth]{illustrations/curvelet_examples/curvelet_1_frequency}\\
                \includegraphics[width=.5\textwidth]{illustrations/curvelet_examples/curvelet_2_frequency}
                \caption{Frequency Domain}
            \end{figure}
        \end{column}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \includegraphics[width=.5\textwidth]{illustrations/curvelet_examples/curvelet_1_time}\\
                \includegraphics[width=.5\textwidth]{illustrations/curvelet_examples/curvelet_2_time}
                \caption{Spatial Domain}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{The Fast Discrete Curvelet Transform}
    \begin{columns}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \input{illustrations/curvelet_tilings/discrete_tiling_freq.tex}
                \caption{Frequency Domain}
            \end{figure}
        \end{column}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \input{illustrations/curvelet_tilings/discrete_tiling_freq_detail.tex}
                \caption{Parallelogram Support}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

\subsection{Feature Extraction}
\begin{frame}{Global Feature Extraction}
    \begin{columns}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \includegraphics[width=.9\textwidth]{illustrations/signature_example_curvelet}
                \caption{Curvelet coefficients at a specific scale and angle}
            \end{figure}
        \end{column}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \includegraphics[width=.9\textwidth]{illustrations/signature_example_curvelet_means}
                \caption{Mean values on an $8 \times 8$ grid}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Local Feature Extraction (Sampling)}
    \begin{description}
        \item[PMEAN] Collect $(n - m + 1)^2$ sample vectors of length $N_s \cdot N_{\theta_s} \cdot m^2$ by concatenating across scales and angles
        \item[PMEAN2] Collect $N_s \cdot (n - m + 1)^2$ sample vectors of length $N_{\theta_s} \cdot m^2$ by concatenating across angles
    \end{description}
    \begin{columns}
        \begin{column}{.5\textwidth}
            \begin{figure}
                \includegraphics[width=\textwidth]{illustrations/signature_example_curvelet_patches}
                \caption{$8 \times 8$ mean coefficient grid sampled using $3 \times 3$ window}
            \end{figure}
        \end{column}
        \begin{column}{.5\textwidth}
            \begin{description}[abc]
                \item[$n$] image width and height
                \item[$m$] window width and height
                \item[$N_s$] Number of scales
                \item[$N_{\theta_s}$] Number of angles at scale $s$
            \end{description}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Local Feature Extraction (Clustering)}
    \begin{itemize}
        \item k-means clustering
        \item Codebook size $k = 1000$
        \item Each sample vector is assigned to the cluster $S_i$, $i = 1, \dots, k$ the center of which it is closest to
        \item Image signature is the number of occurences of each ``visual word'' in the image:
            \begin{equation*}
                \tilde{I} = [|S_1|, |S_2|, \dots, |S_k|]
            \end{equation*}
    \end{itemize}
\end{frame}

\subsection{Ranking}
\begin{frame}{Distance Metrics}
    \begin{description}[Histogram Intersection (HI)] \itemsep16pt
        \item[$L_2$] $d_{EUCL}(p, q) = \sqrt{\sum_{i=1}^n (q_i - p_i)^2}$
        \item[Cosine] $d_{COS}(p, q) = 1 - \frac{p \cdot q}{\|p\| \|q\|}$
        \item[Histogram Intersection (HI)] $d_{HI}(P, Q) = 1 - \frac{\sum_{i=1}^n \min (p_i, q_i)}{\sum_{i=1}^n q_i}$
        \item[Earth Mover's Distance (EMD)] $d_{EMD}(P, Q) = \frac{\sum_{i=1}^n \sum_{j=1}^m d_{i, j} f_{i, j}}{\sum_{i=1}^n \sum_{j=1}^m f_{i, j}}$
    \end{description}
\end{frame}

\begin{frame}{TF-IDF Weighting}
    Term $t_i$ occurs $tc_{i, j}$ times in document $d_j \in D$ with length
    $n_j$ and is present in $m_i$ documents overall.
    \begin{description} \itemsep16pt
        \item[Term Frequency] $tf_{i, j} = \frac{tc_{i, j}}{n_j}$
        \item[Inverse Document Frequency] $idf_{i} = \log \frac{|D|}{m_i}$
        \item[Total Term Weight] $w_{i, j} = tf_{i, j} \cdot idf_{i} = \frac{tc_{i, j}}{n_j} \cdot \log \frac{|D|}{m_i}$
    \end{description}
\end{frame}

%}}}

% results {{{
\section{Results}
\subsection{Cross-Domain Benchmark}
\begin{frame}{Cross-Domain Dataset}
    \begin{figure}
        \includegraphics[width=.3\textwidth]{illustrations/image_examples/sketch_8}
        \includegraphics[width=.3\textwidth]{illustrations/image_examples/result_8_1}
        \includegraphics[width=.3\textwidth]{illustrations/image_examples/result_8_2}\\
        \includegraphics[width=.3\textwidth]{illustrations/image_examples/sketch_13}
        \includegraphics[width=.3\textwidth]{illustrations/image_examples/result_13_1}
        \includegraphics[width=.3\textwidth]{illustrations/image_examples/result_13_2}
        \caption{Example images from ``Sketch-based image retrieval: benchmark and bag-of-features descriptors'', Eitz et al., 2011}
    \end{figure}
\end{frame}

\begin{frame}{Cross-Domain Benchmark}
    \begin{itemize}
        \item 31 user study-based ground-truth rankings of 40 images with
            corresponding query sketches (Eitz et al., 2011)
        \item Kendall rank correlation coefficient $-1 \leq \tau_B \leq 1$
        \item $\tau_B$ is based on the number of similarly ordered pairs of
            measurements between two distributions
        \item $\tau_B = 1$ means same ordering, $\tau_B = -1$ means inverted ordering
        \item independent of the scaling differences between the two distributions
    \end{itemize}
\end{frame}

\begin{frame}{Cross-Domain Results}
    \begin{table}
        \centering
        \pgfplotstableread[]{results/best_performers.csv}\resultsbestperformers
        \plottablexbars{imagereader,features,gridsize,patchsize,cannysigma,metric}{\resultsbestperformers}
        \caption{Best performing pipeline configurations}
    \end{table}
\end{frame}

\begin{frame}{Cross-Domain Distribution}
    \begin{figure}[h]
        \centering
        \pgfplotstableread{results/best_performer_means.csv}\resultsbestperformermeans
        \begin{tikzpicture}
            \begin{axis}[
                ybar,
                small,
                width=\textwidth,
                height=.8\textheight,
                xlabel=Query Images,
                xlabel near ticks,
                ylabel=Mean $\tau_B$ and standard deviation,
                xtick=data,
                xticklabels from table={\resultsbestperformermeans}{key},
                xticklabel style={
                    rotate=90,
                },
                xtick align=inside,
                extra y ticks= 0,
                extra y tick labels=,
                extra y tick style={grid=major},
                axis x line*=box,
                axis y line*=box,
                ymajorgrids,
                error bars/error bar style={
                    gray,
                },
                bar width=5pt,
                ]
                \addplot+[error bars/y dir=both, error bars/y explicit] table[x expr=\coordindex, y=mean, y error=stddev]{\resultsbestperformermeans};
            \end{axis}
        \end{tikzpicture}
        %\caption{Distribution of best performing descriptors across different queries}
    \end{figure}
\end{frame}

\subsection{Intra-Domain Benchmark}
\begin{frame}{Intra-Domain Dataset}
    \begin{figure}
        \begin{tabular}{cccccc}
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/calculator_1.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/calculator_2.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/calculator_3.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/parrot_1.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/parrot_2.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/parrot_3.png} \\
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/donut_1.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/donut_2.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/donut_3.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/doorhandle_1.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/doorhandle_2.png} &
            \includegraphics[width=0.15\textwidth]{illustrations/sketch_examples/doorhandle_3.png}
        \end{tabular}
        \caption{Example sketches from four categories from ``How do humans
            sketch objects?'', Eitz et al., 2012}
    \end{figure}
\end{frame}

\begin{frame}{Intra-Domain Benchmark}
    \begin{itemize}
        \item 50 categories with 80 hand-drawn sketches each (Eitz et al., 2012)
        \item Precision-recall statistics
            \begin{align*}
                recall & = \frac{\text{number of correct positive results}}{\text{total number of positives}} \\
                precision & = \frac{\text{number of correct positive results}}{\text{total number of results}}
            \end{align*}
        \item no edge-detecting preprocessing
    \end{itemize}
\end{frame}

\begin{frame}{Intra-Domain Results}
    \begin{figure}
        \input{illustrations/graphs/pr_precisions_presentation.tex}
    \end{figure}
\end{frame}
%}}}

% conclusion {{{
\section{Conclusions}
\begin{frame}{Discussion and Conclusions}
    \begin{itemize}
        \item Retrieval performance comparable to other descriptors
        \item For cross-domain retrieval, local LUMA+CANNY+HI performs best
        \item For intra-domain retrieval, global descriptors work better
        \item Large performance differences between queries
        \item[$\Rightarrow$] Possibly much better results for narrower problem statements and specialized applications
    \end{itemize}
\end{frame}
%}}}

%}}}
\end{document}
